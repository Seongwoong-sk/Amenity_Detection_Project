{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ayUW39l6-8pj"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Je6WeEsnLB0b"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"id":"cwioPBo18Elt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **<font color='#008080'> 🛠️ 1. Data Preparation</font>**\n","```\n","< Open Datasets - Open Images Dataset v4 >\n","- 1,743,042장의 training 이미지\n","- 41,620장의 validation 이미지\n","- 125,436장의 test 이미지\n","-*14,610,229개의 Bounding box\n","- 600개의 label -> amenity 관련 label 30개만 사용\n","```\n","https://storage.googleapis.com/openimages/web/download.html"],"metadata":{"id":"vg81hXWIlGqd"}},{"cell_type":"markdown","source":["#### **1) class-descriptions-boxable.csv 파일 다운로드**\n","- `class에 대한 id (Open Image Dataset에서 사용하는 class에 대한 id 값)`와 `name(그 id에 대한 human-readable한 string 형태)`값 존재\n","- https://storage.googleapis.com/openimages/web/download_v4.html\n","  - `Metadata` -> `classnames`"],"metadata":{"id":"MXOC52u6mnYf"}},{"cell_type":"markdown","source":["#### **2) Open Images validation dataset 다운로드**\n","- 전체 이미지를 받아서 파싱해주는 과정이 필요\n","- https://github.com/cvdfoundation/open-images-dataset#download-images-with-bounding-boxes-annotations\n","  - `Download from CVDF`\n","\n","전체 Labels 중에서 Amenity와 관련 있는 Label 30개를 사용  \n","\n","전체 이미지를 받기 위해서 아래와 같은 과정 필요\n","```\n","!pip install awscli (라이브러리 설치)\n","!aws s3 --no-sign-request sync s3://open-images-dataset/validation [PATH_TO_SAVE] (aws s3라는 커맨드로 open image dataset을 로컬 컴퓨터로 불러오기)\n","```"],"metadata":{"id":"QsLsakyLnmai"}},{"cell_type":"code","metadata":{"id":"nvBc1LCloyDX"},"source":["!pip install awscli"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zHDknpB9vRk"},"source":["!aws s3 --no-sign-request sync s3://open-images-dataset/validation content/drive/MyDrive/validation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **3) Validation-annotation-bbox.csv 파일 다운로드**\n","- https://storage.googleapis.com/openimages/web/download_v4.html\n","  - `Boxes`\n","- Bounding Box에 대한 정답 포함\n","```\n","ImageId, Source, LabelName, Confidence, XMin, XMax, Ymin, Ymax, IsOcculded, IsTruncated, IsGroupOf, IsDepiction, IsInside\n","```"],"metadata":{"id":"YnzavF6X-fMo"}},{"cell_type":"markdown","source":["# **<font color='#008080'>🎈 2. 전체 이미지에서 Amenity 30개 class가 포함된 이미지만 parsing하기</font>**\n","**File**\n","\n","  - https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/py/open_images_dataset_30_class_parsing.py\n","- 전체 class에서 target으로 잡은 `30개의 Amenity class`에 대응되는 Bounding Box를 포함하고 있는 이미지만을 선별해서 저장\n","\n","\n","`로컬 터미널에서 진행`"],"metadata":{"id":"EwD8uTh_A2EH"}},{"cell_type":"markdown","source":["--------"],"metadata":{"id":"OTkQn5mIOKRT"}},{"cell_type":"markdown","source":["# **<font color='#008080'>🍯 3. Train 데이터셋에서도 30 Amenity Class Parsing</font>**\n","**File**\n","  - https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/py/open_images_dataset_30_class_parsing.py\n","- https://github.com/cvdfoundation/open-images-dataset#download-images-with-bounding-boxes-annotations\n","- validation data 탐색 결과 minor한 class는 데이터의 수가 현저히 적어서 Train Dataset에서 513GB짜리 데이터에서 30개 파싱\n","\n","**이미 작업완료된 Train Dataset**\n","- https://drive.google.com/file/d/13M2PifJzC1e-kdc8wYBXdbprNpOdwodk/view?usp=sharing \n","\n","\n","`로컬 터미널에서 진행`\n"],"metadata":{"id":"TorhbFMgWjO7"}},{"cell_type":"markdown","source":["-----------------"],"metadata":{"id":"jR2ShW5KGGzd"}},{"cell_type":"markdown","source":["\n","# **<font color='#008080'>🍖 4. Amenity 30개 class에 대한 pbtxt 파일 생성</font>**\n","- pbtxt\n","  - label id-name mapping files\n","  - TFRecord 변환할 때, Train할 때 사용\n","\n","- https://github.com/tensorflow/models/blob/master/research/object_detection/data/oid_v4_label_map.pbtxt\n","  - 여기에 Open Image Dataset 601개의 클래스에 대한 id & name값이 들어있는데 여기서 Amenity와 관련된 30개 클래스와 관련된 값 추출해서 사용\n","\n","**File**\n","  - https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/oid_v4_label_map_amenity_30_class.pbtxt\n","\n","`로컬 터미널에서 진행`\n"],"metadata":{"id":"iBp0Oo9Le-es"}},{"cell_type":"markdown","metadata":{"id":"VuY5BHGFfCaO"},"source":["------"]},{"cell_type":"markdown","source":["# **<font color='#008080'>🎇 5. Amenity 데이터 TFRecord 변환하기</font>**\n","**File**\n","  - https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/py/create_oid_v4_tf_record.py\n","- 30개 클래스만 파싱해서 가져왔는데, 그 데이터를 토대로 학습에 필요한 형태로 학습할 수 있는 `TFRecord 형태로 변환`\n","- https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/create_pet_tf_record.py\n","  - `Oxford IIT Pet Dataset의 TFRecord를 생성하는 코드`에서 Custom에 맞게 `수정`한 파이썬 파일을 변환해서 코드 사용\n","\n","  \n","`로컬 터미널에서 진행`\n","\n","`Train TFRecord`\n","- 용량이 커서 구글 드라이브 공유 링크 생성\n","- https://drive.google.com/file/d/19n6B2FKK3LbfzaVQv3FIy4E2OWvxFb6k/view?usp=sharing, https://drive.google.com/file/d/1D38i2zFLl1tNxawvt2A0C-C_OlWaegx_/view?usp=sharing, https://drive.google.com/file/d/1DZo3guWIG35hKDi4bDC2Q4-nLJpn1QQ1/view?usp=sharing, https://drive.google.com/file/d/1eGG0Df5wh4uNkcq-U7VzvxRYnbv8_F8l/view?usp=sharing, https://drive.google.com/file/d/1yYdV97hK_o5_Jso-P8PSeF2tc0OxEXYH/view?usp=sharing\n","\n","\n","`Validation TFRecord`\n","- 용량이 커서 구글 드라이브 공유 링크 생성\n","- https://drive.google.com/file/d/129RbbrjA1sKrfPpLFhpeyvb5Ab0AVGcn/view?usp=sharing, https://drive.google.com/file/d/1TVrXjCTl7B5_yDG6Milhy7tNhRRcqY4d/view?usp=sharing, https://drive.google.com/file/d/1aadNiuexNdHDuhdVyVm3lgRrI6AETwxI/view?usp=sharing, https://drive.google.com/file/d/1i9KSrbsRBHupTrMxeMlTS6ZyfaG1sqXF/view?usp=sharing, https://drive.google.com/file/d/1lEKdtqcMWixUTiufw2QU6ze6OnpGd8pX/view?usp=sharing"],"metadata":{"id":"bCRd3uKG2e8x"}},{"cell_type":"markdown","source":["--------"],"metadata":{"id":"DBonPcc5M5hB"}},{"cell_type":"markdown","source":["# **<font color='#008080'>✨ 6. Amenity Detection을 위한 config 파일 생성</font>**\n","- Model Configuration files\n","- `Tensorflow Object Detection API` 제공하는 다양한 모델들 중 `어떤 모델을 사용할 것인지 결정`하는 부분\n","\n","- https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n","- https://github.com/tensorflow/models/blob/master/research/object_detection/configs/tf2/centernet_hourglass104_512x512_coco17_tpu-8.config  \n","  - `MS-COCO Dataset`에 맞게 학습시키게 맞춰진 config 파일이라 Custom에 맞게 수정\n","  \n","  **수정**\n","  - `num_classes`, `batch_size`, `fine_tuned checkpoint`, `train, eval_input_reader`\n","\n","**File**\n","  - https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/centernet_hourglass104_512x512_amenity_30class.config\n"],"metadata":{"id":"yehtknLF2jpX"}},{"cell_type":"markdown","source":["--------"],"metadata":{"id":"omg9I7s0W8YH"}},{"cell_type":"markdown","source":["# **<font color='#008080'>⚡ 7. pbtxt, config, tfrecord를 이용한 CenterNet을 이용한 Amenity Detection Training</font>**"],"metadata":{"id":"MUNZbW9d2j5v"}},{"cell_type":"code","metadata":{"id":"oBq_BO3x2j8R"},"source":["!git clone https://github.com/tensorflow/models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Luqwzg8iWzm"},"source":["%cd models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AQytE7mviYWC"},"source":["# tensorflow/models repository 자체가 잦은 변경이 이뤄지다 보니깐 버전 변경의 문제가 생김. \n","# 이러한 문제가 생기지 않도록 안정적인 commit 시점으로 git reset\n","\n","!git reset --hard d7ce106b8ea449cc629569ca43a95e55a18807fa"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nyaWy-gliaN8"},"source":["%cd models/research\n","!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaGE-afSkVll"},"source":["# 관련된 protoc Compile.\n","\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EUxoYD1O2j-f"},"source":["# Install TensorFlow Object Detection API.\n","\n","!cp object_detection/packages/tf2/setup.py ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EmJFSs4MZ2YK"},"source":["# pip version upgrade\n","\n","!python -m pip install --upgrade pip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-CXTsJri3rI"},"source":["!python -m pip install --use-feature=2020-resolver ."],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"XdI_OHDB2ERp"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aW5z1cLhi3w9"},"source":["# test script를 실행해서 Tensorflow Object Detection API가 잘 설치됐는지 확인\n","\n","!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **1) Amenity Detection용 TFRecord 경로 설정**"],"metadata":{"id":"CwxwGr8Qi30I"}},{"cell_type":"code","metadata":{"id":"vf4ZvTda2cGI"},"source":["# TFRecord\n","# /content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **2) pbtxt 파일 Download**\n","\n","**Reference**\n","- https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/oid_v4_label_map_amenity_30_class.pbtxt"],"metadata":{"id":"GxeMFkpJi32l"}},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"1SW7f2I1GMiH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HbxqjhDykw3Q"},"source":["# 다운로드 받은 oid_v4_label_map_amenity_30_class.pbtxt 파일을 models/research/object_detection/data/ 경로에 업로드\n","\n","!wget https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/oid_v4_label_map_amenity_30_class.pbtxt -O /content/models/research/object_detection/data/oid_v4_label_map_amenity_30_class.pbtxt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **3) Training을 위한 config 파일 Download**\n","\n","**Reference**\n","- https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/centernet_hourglass104_512x512_amenity_30class.config"],"metadata":{"id":"yOp-OBvJkw6I"}},{"cell_type":"code","metadata":{"id":"tXdJ46TI-Wsh"},"source":["# config\n","\n","%cd /content/models/research"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZMGIVwA1kw-d"},"source":["# github에서 raw누르고 링크로 다운 !wget\n","!wget https://github.com/Seongwoong-sk/Amenity_Detection_Project/blob/main/centernet_hourglass104_512x512_amenity_30class.config"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**pbtxt 내 경로 변경**\n","\n","- /content/models/research/object_detection/data/oid_v4_label_map_amenity_30_class.pbtxt안의 `train_input_reader`, `eval_input_reader` 경로 변경"],"metadata":{"id":"A8OXSTSpWLnJ"}},{"cell_type":"code","metadata":{"id":"NqgXOOCOkxBj"},"source":["!pwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p-_2p6LlkxGI"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **4) Training 전 환경 세팅**"],"metadata":{"id":"TDqrhyRCWpf7"}},{"cell_type":"code","metadata":{"id":"jwVPViZAvHlE"},"source":["# pbtxt -->  models/research/object_detection/data/\n","# tfrecord --> Custom Path/\n","\n","# From the tensorflow/models/research/      \n","PIPELINE_CONFIG_PATH=\"centernet_hourglass104_512x512_amenity_30class.config\"\n","\n","#MODEL_DIR=\"./saved_result_licenseplate\" Training한 모델의 Checkpoint가 저장될 경로 설정\n","MODEL_DIR=\"/content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/saved_model\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9-LYGfGzvlTz"},"source":["# 원활한 GPU 연결을 위해 다운그레이드\n","\n","!python -m pip install tensorflow==2.4.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OpenCV 버전 호환\n","\n","!pip uninstall opencv-python-headless==4.5.5.62\n","!pip install opencv-python-headless==4.5.2.52"],"metadata":{"id":"beOlqz0N9RFu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### **5) Training**\n","\n","- 학습 전 `object_detection/model_main_tf2.py` 내 with `strategy.scope 구문`에서 model_lib_v2.train_loop의 checkpoint_max_to_keep=`iteration num to save checkpoint` 인자 추가\n","- 최근 checkpoint를 통해 학습이 끊어져도 이어서 학습이 가능\n","\n","**학습이 끊어졌을때**\n","- checkpoint를 클릭해서 \n","  - model_checkpoint_path : \n","  - all_model_checkpoint_paths: \n","- 이 두 인자를 \"ckpt-최신 숫자\" 입력하고 스크립트를 실행하면 끊긴 시점을 기점으로 이어서 Resume Training을 진행한다."],"metadata":{"id":"iZansXKLwLKz"}},{"cell_type":"code","metadata":{"id":"PnAj8EXPNg-R"},"source":["# checkpoint_max_to_keep=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m7F4Xg33wLyd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643954639559,"user_tz":-540,"elapsed":2788148,"user":{"displayName":"Sw K","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17959898805417636363"}},"outputId":"c2c1aa46-a098-4bd0-8916-5ea11e062e00"},"source":["!python object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n","    --model_dir={MODEL_DIR} \\\n","    --alsologtostderr"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-02-04 05:17:28.440260: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-02-04 05:17:31.363891: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-02-04 05:17:31.365067: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2022-02-04 05:17:31.381433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.382333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2022-02-04 05:17:31.382371: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-02-04 05:17:31.395388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-02-04 05:17:31.395504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2022-02-04 05:17:31.396572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-02-04 05:17:31.396920: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-02-04 05:17:31.594842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2022-02-04 05:17:31.595830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-02-04 05:17:31.596052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-02-04 05:17:31.596211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.597173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.597970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2022-02-04 05:17:31.598694: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2022-02-04 05:17:31.598895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.599863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n","pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\n","coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\n","2022-02-04 05:17:31.599899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-02-04 05:17:31.599963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-02-04 05:17:31.600030: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","2022-02-04 05:17:31.600097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n","2022-02-04 05:17:31.600143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n","2022-02-04 05:17:31.600186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n","2022-02-04 05:17:31.600229: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n","2022-02-04 05:17:31.600272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-02-04 05:17:31.600391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.601359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:31.602198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n","2022-02-04 05:17:31.602253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","2022-02-04 05:17:32.282352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2022-02-04 05:17:32.282405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n","2022-02-04 05:17:32.282430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n","2022-02-04 05:17:32.282733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:32.283660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:32.284538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-02-04 05:17:32.285377: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-02-04 05:17:32.285433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14957 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0204 05:17:32.287538 139671384127360 mirrored_strategy.py:350] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0204 05:17:32.292003 139671384127360 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0204 05:17:32.292160 139671384127360 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0204 05:17:33.029099 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:531: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/oid_30_class_train.record-?????-of-00005']\n","I0204 05:17:33.043062 139671384127360 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/oid_30_class_train.record-?????-of-00005']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/oid_30_class_train.record-?????-of-00005']\n","I0204 05:17:33.047669 139671384127360 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/Colab_Notebooks/Personal_Project/Amenity_Detection_Project/Airbnb_Project/oid_30_class_train.record-?????-of-00005']\n","INFO:tensorflow:Number of filenames to read: 5\n","I0204 05:17:33.047802 139671384127360 dataset_builder.py:81] Number of filenames to read: 5\n","WARNING:tensorflow:num_readers has been reduced to 5 to match input file shards.\n","W0204 05:17:33.047884 139671384127360 dataset_builder.py:88] num_readers has been reduced to 5 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0204 05:17:33.050149 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0204 05:17:33.070064 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0204 05:17:41.067863 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0204 05:17:44.688399 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0204 05:17:48.097689 139671384127360 deprecation.py:339] From /usr/local/lib/python3.7/dist-packages/object_detection/inputs.py:282: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2022-02-04 05:17:52.824249: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n","2022-02-04 05:17:52.830468: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0204 05:28:08.288726 139667294627584 deprecation.py:537] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","2022-02-04 05:28:59.790299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n","2022-02-04 05:29:10.939808: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n","2022-02-04 05:29:12.161206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n","INFO:tensorflow:Step 137100 per-step time 0.673s loss=4.883\n","I0204 05:30:21.094186 139671384127360 model_lib_v2.py:659] Step 137100 per-step time 0.673s loss=4.883\n","INFO:tensorflow:Step 137200 per-step time 0.671s loss=4.677\n","I0204 05:31:28.146258 139671384127360 model_lib_v2.py:659] Step 137200 per-step time 0.671s loss=4.677\n","INFO:tensorflow:Step 137300 per-step time 0.657s loss=4.439\n","I0204 05:32:35.517307 139671384127360 model_lib_v2.py:659] Step 137300 per-step time 0.657s loss=4.439\n","INFO:tensorflow:Step 137400 per-step time 0.650s loss=5.873\n","I0204 05:33:42.256361 139671384127360 model_lib_v2.py:659] Step 137400 per-step time 0.650s loss=5.873\n","INFO:tensorflow:Step 137500 per-step time 0.674s loss=4.231\n","I0204 05:34:49.308448 139671384127360 model_lib_v2.py:659] Step 137500 per-step time 0.674s loss=4.231\n","INFO:tensorflow:Step 137600 per-step time 0.664s loss=6.619\n","I0204 05:35:56.486787 139671384127360 model_lib_v2.py:659] Step 137600 per-step time 0.664s loss=6.619\n","INFO:tensorflow:Step 137700 per-step time 0.668s loss=5.930\n","I0204 05:37:03.505969 139671384127360 model_lib_v2.py:659] Step 137700 per-step time 0.668s loss=5.930\n","INFO:tensorflow:Step 137800 per-step time 0.684s loss=3.667\n","I0204 05:38:10.684556 139671384127360 model_lib_v2.py:659] Step 137800 per-step time 0.684s loss=3.667\n","INFO:tensorflow:Step 137900 per-step time 0.680s loss=4.029\n","I0204 05:39:17.658733 139671384127360 model_lib_v2.py:659] Step 137900 per-step time 0.680s loss=4.029\n","INFO:tensorflow:Step 138000 per-step time 0.668s loss=4.991\n","I0204 05:40:25.008075 139671384127360 model_lib_v2.py:659] Step 138000 per-step time 0.668s loss=4.991\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.315742 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.316981 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.319774 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.320863 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.323980 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.324972 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.327776 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.328762 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.331165 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0204 05:40:25.332083 139671384127360 cross_device_ops.py:565] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Step 138100 per-step time 0.684s loss=4.104\n","I0204 05:41:51.102271 139671384127360 model_lib_v2.py:659] Step 138100 per-step time 0.684s loss=4.104\n","INFO:tensorflow:Step 138200 per-step time 0.690s loss=5.159\n","I0204 05:42:59.029466 139671384127360 model_lib_v2.py:659] Step 138200 per-step time 0.690s loss=5.159\n","INFO:tensorflow:Step 138300 per-step time 0.706s loss=3.794\n","I0204 05:44:06.853163 139671384127360 model_lib_v2.py:659] Step 138300 per-step time 0.706s loss=3.794\n","INFO:tensorflow:Step 138400 per-step time 0.694s loss=2.974\n","I0204 05:45:14.826453 139671384127360 model_lib_v2.py:659] Step 138400 per-step time 0.694s loss=2.974\n","INFO:tensorflow:Step 138500 per-step time 0.675s loss=3.477\n","I0204 05:46:22.844202 139671384127360 model_lib_v2.py:659] Step 138500 per-step time 0.675s loss=3.477\n","INFO:tensorflow:Step 138600 per-step time 0.667s loss=5.426\n","I0204 05:47:30.834499 139671384127360 model_lib_v2.py:659] Step 138600 per-step time 0.667s loss=5.426\n","INFO:tensorflow:Step 138700 per-step time 0.666s loss=5.599\n","I0204 05:48:38.474353 139671384127360 model_lib_v2.py:659] Step 138700 per-step time 0.666s loss=5.599\n","INFO:tensorflow:Step 138800 per-step time 0.690s loss=3.930\n","I0204 05:49:46.483692 139671384127360 model_lib_v2.py:659] Step 138800 per-step time 0.690s loss=3.930\n","INFO:tensorflow:Step 138900 per-step time 0.684s loss=3.964\n","I0204 05:50:54.300716 139671384127360 model_lib_v2.py:659] Step 138900 per-step time 0.684s loss=3.964\n","INFO:tensorflow:Step 139000 per-step time 0.675s loss=7.280\n","I0204 05:52:02.143079 139671384127360 model_lib_v2.py:659] Step 139000 per-step time 0.675s loss=7.280\n","INFO:tensorflow:Step 139100 per-step time 0.693s loss=4.464\n","I0204 05:53:26.498104 139671384127360 model_lib_v2.py:659] Step 139100 per-step time 0.693s loss=4.464\n","INFO:tensorflow:Step 139200 per-step time 0.683s loss=3.545\n","I0204 05:54:34.231753 139671384127360 model_lib_v2.py:659] Step 139200 per-step time 0.683s loss=3.545\n","INFO:tensorflow:Step 139300 per-step time 0.669s loss=2.693\n","I0204 05:55:41.907355 139671384127360 model_lib_v2.py:659] Step 139300 per-step time 0.669s loss=2.693\n","INFO:tensorflow:Step 139400 per-step time 0.661s loss=6.034\n","I0204 05:56:49.605061 139671384127360 model_lib_v2.py:659] Step 139400 per-step time 0.661s loss=6.034\n","INFO:tensorflow:Step 139500 per-step time 0.678s loss=4.065\n","I0204 05:57:57.645478 139671384127360 model_lib_v2.py:659] Step 139500 per-step time 0.678s loss=4.065\n","INFO:tensorflow:Step 139600 per-step time 0.656s loss=6.218\n","I0204 05:59:05.043896 139671384127360 model_lib_v2.py:659] Step 139600 per-step time 0.656s loss=6.218\n","INFO:tensorflow:Step 139700 per-step time 0.694s loss=4.551\n","I0204 06:00:12.246786 139671384127360 model_lib_v2.py:659] Step 139700 per-step time 0.694s loss=4.551\n","INFO:tensorflow:Step 139800 per-step time 0.688s loss=5.909\n","I0204 06:01:19.727710 139671384127360 model_lib_v2.py:659] Step 139800 per-step time 0.688s loss=5.909\n","INFO:tensorflow:Step 139900 per-step time 0.673s loss=6.507\n","I0204 06:02:27.003925 139671384127360 model_lib_v2.py:659] Step 139900 per-step time 0.673s loss=6.507\n","INFO:tensorflow:Step 140000 per-step time 0.679s loss=3.629\n","I0204 06:03:34.304975 139671384127360 model_lib_v2.py:659] Step 140000 per-step time 0.679s loss=3.629\n"]}]}]}